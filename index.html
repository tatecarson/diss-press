<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <style>
    .container {
      position: relative;
      width: 100%;
      overflow: hidden;
      padding-top: 100%;
      /* 1:1 Aspect Ratio */
    }

    .responsive-iframe {
      position: absolute;
      top: 0;
      left: 0;
      bottom: 0;
      right: 0;
      width: 100%;
      height: 100%;
      border: none;
    }
  </style>
  <title>Participatory mobile music with smartphones</title>
  <link href="big.css" rel="stylesheet" type="text/css" />
  <link href="themes/charleston.css" rel="stylesheet" type="text/css" />

  <script src="js/index-citations-global.js"></script>
  <script>
    function run() {
      IndexCitations({
        referenceId: "#citations",
      });

      const citations = document.querySelectorAll(".citationLink");
      // TODO: update this to be the last slide whenever you make it
      citations.forEach((citation) => (citation.href = "#53"));

      const ref = document.querySelectorAll("#citations cite");

      ref.forEach((reference) => {
        var el = document.createElement("span");
        el.innerHTML = '<a href="javascript:history.back()">&#8627;</a>';
        insertAfter(reference, el);
      });
    }

    if (document.readyState != "loading") {
      run();
    } else {
      document.addEventListener("DOMContentLoaded", run);
    }

    function insertAfter(referenceNode, newNode) {
      referenceNode.parentNode.insertBefore(
        newNode,
        referenceNode.nextSibling
      );
    }
  </script>
  <script src="big.js"></script>
  <script src="js/lazysizes.min.js"></script>
</head>

<body>

  <div>
    <div>Using Distributed Technology to Make Music in the time of the Attention Economy</div>
    <div>
      <em> Tate Carson, MM, MFA </em>
    </div>
    <notes></notes>
  </div>

  <div>Theoretical Background</div>

  <div>Attention Economy</div>

  <div>Ecological Awareness</div>

  <div>Restorative Environments</div>

  <div>Distributed Internet</div>

  <div>Artistic Background</div>

  <div>Soundwalking</div>

  <div>GPS Soundwalks</div>

  <div>Distributed Internet</div>

  <div>Sonification</div>

  <div>Previous work</div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/nature3.jpg" alt="Sounds Aware" />

    <div>Sounds Aware (2019) - Version 1</div>

    <notes>Sounds Aware is a web application that runs on a smartphone and uses
      machine learning to detect human-made sound (anthrophony) and masks it
      with ambient music as a user walks around their environment. Though the
      model is pre-trained with the author’s local environmental sounds, the
      user can train the model further on their unique soundscape so that each
      user gets a personalized experience. After the training process, the
      user can listen to ambient music based on traits of the surrounding
      anthrophony. If the app senses less anthrophony and more biophony or
      geophony, then the music fades away, bringing the user’s attention to
      the anthrophony.</notes>
  </div>
  <div class="layout">
    <img src="images/soundsaware/walkingDog.jpg" alt="" />
    <notes>The idea for Sounds Aware came while walking with dog Lucy around the
      lakes by my house. When I first started walking her I would listen to
      podcast or music on headphones for the entire walk because I found it
      difficult to fill the time with my own thoughts. I would hear the sounds
      of nature occasionally coming through my music and this made me want to
      take the head phones out and just listen.</notes>
  </div>
  <div class="layout">
    <img src="images/soundsaware/nature.jpg" alt="" />

    <notes>The problem came when I tried to do that and realized there, while this
      is a beautiful bit of nature, it is by peoples houses and some major
      roads.</notes>
  </div>

  <div class="layout">
    <img src="images/soundsaware/construction.jpg" alt="" />
    <notes>So in addition the birds I could also hear the noise of lawnmowers,
      home construction and cars driving by.</notes>
  </div>
  <div class="layout">
    <video src="images/soundsaware/constructionVid.mp4" width="500px" controls></video>
    <notes>And sometimes it sounds like this. This made me want the best of both
      worlds. I wanted to create a system that would play music if it heard
      'noise' and play nothing if it heard nothing. This I thought would help
      me focus my attention more on nature and less on how much I didn't want
      to hear the noise. This inspired Sounds Aware.</notes>
  </div>
  <div>
    <blockquote>
      <p>
        To what extent might the technologies of communication, art and
        entertainment serve as 'prostheses' that would provide us with
        experiences of wilderness that would not only enrich our human
        identity but help us to preserve and expand the domain of the
        non-human world?
      </p>
      <cite>
        David Dunn. Wilderness as Reentrant Form: Thoughts on the Future of
        Electronic Art and Nature. Leonardo, (4):377, 1988.
      </cite>
    </blockquote>
    <div>- David Dunn</div>

    <notes> Composer David Dunn poses an inspirational question: </notes>
  </div>
  <div>
    A goal of Sounds Aware is to shift attention to geophonic and biophonic
    soundscape away from the anthrophonony.

    <notes>
      The goal of Sounds Aware is to bring the user’s awareness to the
      geophonic and biophonic soundscape, which is often so masked by noise
      pollution that it has fallen out of awareness for many of us. Sounds
      Aware seeks to shift the user’s concept of nature to something that has
      no starting or end- ing point; it is all around us. The app brings
      awareness by focusing attention on the environment. Because of the pre-
      dominance of eye culture [3], our reliance on seeing rather than
      listening as a primary means of sensing the world, it is a lot to ask of
      a person who might be uninterested in acoustic ecology to “just listen”
      to their environment. But, if you give them a tool that urges listening
      in the quieter places, where the natural world will be more audible,
      there is a better chance of them engaging with those sounds because the
      app focused their perception. Sounds Aware is a means of technologically
      mediated “ear cleaning,” as described by R. Murray Schafer in Ear
      Cleaning: Notes for an Experimental Music Course [13].
    </notes>
  </div>
  <div>
    <div>Noise Pollution</div>
    <div>
      <ul>
        <li>
          There is overwhelming evidence that exposure to environmental noise
          has adverse effects on the health of the population.<cite>World Health Organization, Burden of disease from
            environmental
            noise: Quantification of healthy life years lost in Europe. World
            Health Organization. Regional Office for Europe, 2011.
          </cite>
        </li>
        <li>
          Sounds Aware will make users more aware of how much harmful noise
          they experience in their daily lives.
        </li>
      </ul>
    </div>
    <notes>A 2011 World Health Organization (WHO) report found that “there is
      overwhelming evidence that exposure to environmental noise has adverse
      effects on the health of the population [10].” Sounds Aware shifts a
      users attention away from noise pollution and to nature, which may help
      mitigate adverse health effects caused by noise pollution.
      <br />
      While a reduction in environmental noise at the source would be the best
      way to solve noise pollution, masking the noise is a stopgap solution. A
      masking solution has been implemented by several projects [9, 15] but
      not yet with a mobile device. Sounds Aware implements a similar idea but
      with a mobile phone.
    </notes>
  </div>


  <div>
    <div>
      <ul>
        <li>
          Stress reduction can be aided by the experience of the natural
          environment by providing a ‘restorative environment’ that reduces
          the fatigue caused by directed attention.<cite>Stephen. Kaplan, “The restorative benefits of nature: toward an
            integrative framework.,” In: Journal of Environmental Psychology.,
            vol. 15, pp. 169–182, 1995.
          </cite>
        </li>
        <li>
          Bird sounds may provide restorative benefits.<cite>E. Ratcliffe, B. Gatersleben, and P. T. Sowden, “Bird
            sounds and
            their contributions to perceived attention restoration and stress
            recovery,” Journal of Environmental Psychology, vol. 36, pp.
            221–228, 2013.
          </cite>
        </li>
      </ul>
    </div>
    <notes>Psychologist Stephen Kaplan found that stress reduction can be aided by
      the experience of the natural environment by providing a ‘restorative
      environment’ that reduces the fatigue caused by directed attention [8].
      Kaplan did not mention sound directly, but a recent study by Eleanor
      Ratcliffe et al [12] has extended his research to show that certain bird
      sounds may provide restorative benefits.</notes>
  </div>

  <div>
    <div>R. Murray Schafer's Soundscape</div>
    <div>
      <ul>
        <li>rural landscape - hi-fi</li>
        <li>urban landscape - lo-fi</li>
      </ul>
    </div>
    <notes>R. Murray Schafer suggests that we should listen to the environment as
      a musical composition. He describes urban and rural soundscapes as lo-fi
      and hi-fi. A rural landscape is hi-fi because there is a low noise level
      and allows one to hear more clearly. When in lo-fi (urban) soundscapes
      we are deal- ing with a lot of sound masking and getting less
      discernible aural information [14]. Sounds Aware brings attention to
      that urban noise by masking it with music, possibly reducing its
      negative effects as described by the WHO report [10]. The music of
      Sounds Aware and Schafer’s ‘environment as musical composition’ combine
      as a duet to create a new un- heard work.</notes>
  </div>


  <div>
    <div>Audio Walks</div>
    <blockquote>
      <p>
        experiments and works that combine walking and listening to a mediated
        soundscape over headphones.
        <cite>J. Steindorf. Walk-Along with a Mediated Presence: The Audio Walk
          as a Mobile Method. Wi: Journal of Mobile Media, 2017.</cite>
      </p>
    </blockquote>
    <div>- Johanna Steindorf</div>
    <notes>
      Sounds Aware is further classified as an audio walk because it is a
      soundwalk mediated by technology. Johanna Steindorf describes audio
      walks as “experiments and works that combine walking and listening to a
      mediated sound- scape over headphones [16].” That an audio walk takes
      place using headphones is important because it adds “a second layer of
      private sound to any place and situation, there- fore transforming or
      enhancing the current spatial experience [16].” Sounds Aware mediates
      the public space through remediation of noise. The unique part of this
      audio walk is that the user is meant to be more aware when the composed
      ambient music is off. It is almost like a negative audio walk.
    </notes>
  </div>
  <div>Related Work</div>
  <div class="layout" style="
        grid-template-columns: repeat(6, 1fr);
        grid-template-rows: repeat(5, 1fr);
        grid-column-gap: 11px;
      ">
    <div style="grid-area: 1 / 1 / 3 / 7">
      The Quiet Walk - Alessandro Altavilla and Atau Tanaka
    </div>
    <img style="grid-area: 3 / 1 / 6 / 4" src="images/soundsaware/TQW-MapsOnApp-620x348.jpg" alt="" />
    <img style="grid-area: 3 / 4 / 6 / 7" src="images/soundsaware/TQW-MobileAppInUse-620x348.jpg" alt="" />
    <notes>
      The Quiet Walk [1], by Alessandro Altavilla and Atau Tanaka, is locative
      audio walk artwork for explorations of the urban landscape, where the
      goal is to find the quietest place in an urban location. The app
      notifies users if the surrounding sounds are too high. It also records
      the GPS locations of quiet places that are found so that the user can
      view a sound map of their walk.
    </notes>
  </div>
  <div class="layout" style="grid-template-rows: 25% 75%">
    <div>Ambient Walk - Chen, Bowers, Durrant</div>
    <div>
      <img src="images/soundsaware/ambientWalk.jpg" alt="" />
    </div>
    <notes>
      Chen, Bowers, Durrant created Ambient Walk [4], a mobile application
      that encourages mindful walking through sonification of biophysical
      data. The app plays ambient music dependent on users breathing patterns
      and the pace of walking. The authors intend for the music to keep a user
      aware of their ‘balancing status’ between walking and breathing. The
      intentions of Ambient Walk are very similar to Sounds Aware, though its
      intention is to raise the user’s awareness of one’s own
      mindfulness,instead of the soundscape.
    </notes>
  </div>

  <div>
    <div>Design</div>
    <div>
      <ul>
        <li>Tone.js</li>
      </ul>
    </div>
    <notes>Sounds Aware is built with Tone.js, a Web Audio API framework. There
      are a few downsides to web-based apps, such as cross-browser
      compatibility issues with microphone input, but a web app was chosen
      because a user might be more likely to try it if they do not have to
      download an app.</notes>
  </div>

  <div>
    <div>Data Tags</div>
    <div>
      <ul>
        <li>Geophony - wind, other weather, rain</li>
        <li>Anthrophony - cars, construction, human speech, AC, airplanes</li>
        <li>Biophony - insects, birds, large animal</li>
      </ul>
    </div>
    <notes>Each user starts off with an author-defined database of tagged sounds.
      To create this database each recording made was tagged (see Table 1)
      with a general sound category. Those sounds were then placed into
      broader categories of origin. This allowed the composition to treat
      sounds from different sources—geophony, anthrophony, and biophony—
      differently.
    </notes>
  </div>

  <div>
    <div>Machine listening</div>
    <ul>
      <li>Meyda.js - <a href="http://meydajs.org">http://meydajs.org</a></li>
    </ul>
    <notes>The app uses machine learning to identify sounds. The al- gorithm used
      is k-nearest neighbor. A Mel-Frequency Cep- stral Coefficients (MFCC)
      audio feature was used to com- pare sounds, implemented by Meyda.js1 , a
      JavaScript fea- ture extraction library. Using Meyda.js allowed the
      process- ing to be done on the client, allowing Sounds Aware to work
      offline when necessary.</notes>
  </div>

  <div>
    <div>Composition</div>
    <div>
      <ul>
        <li>Influenced by ambient music</li>
        <li>Influenced by Aeolian practices</li>
        <li>
          Tuned using La Monte Young's just intonation Well-Tuned Piano tuning
        </li>
      </ul>
    </div>

    <notes>The musical composition of Sounds Aware is influenced by ambient music.
      Synthesized sounds were used that would not be too jarring to jump in
      and out of and did not have an obvious beginning or ending. This type of
      synthesized sound blends in with the surrounding acoustic environment as
      a composition. The synthesized sounds are simple frequency modulation
      synthesis with reverb and delay effects. They are tuned to just
      intervals so they are more likely to coincide with tunings in nature,
      influenced by Aeolian practices [2] and La Monte Young [6].</notes>
  </div>

  <div class="layout" style="grid-template-rows: 25% 75%">
    <div>Mapping</div>
    <div>
      <img src="images/soundsaware/compDesign.svg" alt="" />
    </div>

    <notes>
      The app maps the loudness of the acoustic environment to the amplitude
      of the ambient composition (see Figure 2). The previous 200 loudness
      values are averaged and the am when a user was moving. If they had been
      added to the anthrophony the system would only work if the user was
      still and silent; this was a trade-off to allow for user mobil- ity,
      allowing them to find various soundscapes. More data plitude ramps to a
      given value over one second for signal smoothing. If Sounds Aware hears
      an anthrophonic sound, the amplitude is faded up to -3 dB. If it hears a
      geophonic sound, the amplitude of the geophonic sound is mapped onto the
      synthesized sounds amplitude, creating a wind chime ef- fect. Geophonic
      sounds also affect the modulation index and harmonicity of the frequency
      modulation synthesis, cre- ating a variety of timbres depending on the
      character of the current external soundscape. If a biophonic sound is
      recog- nized, the amplitude of the ambient wash is faded down to -59 dB,
      which is perceptibly silent when listened to in an urban environment.
    </notes>
  </div>

  <div>
    <div>What did I learn?</div>
    <ul>
      <li>The app would be more useful with user accounts.</li>
      <li>
        User training of the machine learning algorithm directly on the phone
        is not accurate enough to understand more than a few sounds but might
        be viable in the future.
      </li>
    </ul>
  </div>

  <div>Project Design</div>

  <div>Sounds Aware App Tour</div>

  <div>Home screen</div>

  <div class="layout">
    <video src="videos/home-page.mp4" width="500px" height="1000px" controls></video>
    <notes>The discover page shows each soundwalk created by other users</notes>
  </div>

  <div>Discover screen</div>

  <div class="layout">
    <video src="videos/discover-page.mov" width="500px" height="1000px" controls></video>
    <notes>The discover page shows each soundwalk created by other users</notes>
  </div>

  <div>Going on a soundwalk (walking the dog)</div>

  <!-- <div class="layout">
    <video
      src="videos/goingOnSoundwalk.mp4"
      width="500px"
      height="1000px"
      controls
    ></video>
    <notes
      >Here I go on the dog walk soundwalk I had created earlier</notes
    >
  </div> -->

  <div>
    <iframe width="1000px" height="700px" src="https://www.youtube.com/embed/mpr_-GG7zno" title="YouTube video player"
      frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
      allowfullscreen></iframe>

  </div>

  <div>Creating a soundwalk</div>

  <div class="layout">
    <video src="videos/stop-1.m4v" width="500px" controls></video>
    <notes>This is the start of the walk. Its pretty quiet but you can hear some noise in the background</notes>
  </div>
  <div class="layout">
    <video src="videos/stop1-phone.mov" width="500px" controls></video>
    <notes>and this is what the phone interaction looked like</notes>
  </div>

  <div class="layout">
    <video src="videos/lakeStop.m4v" width="500px" controls></video>
    <notes>Then there was another stop at the lake</notes>
  </div>


  <div class="layout">
    <video src="videos/lakeStop-phone.mov" width="500px" controls></video>
    <notes>and the phone looked like this</notes>
  </div>

  <div>How is the app made?</div>

  <div>
    Planning Process - Figma

    <notes>Before starting to develop the app I made a design in Figma, a tool for prototyping apps. The great thing
      about Figma is that it allows you to prototype interactions as well as the interface. This helps you reason about
      how the app will work before getting lost in the code.</notes>
  </div>


  <div id="citations">References</div>
  <div>
    <div>Thank You</div>
    <em> tcarso2@lsu.edu </em>
    <a href="https://tatecarson.com" target="blank">https://tatecarson.com</a>
  </div>
  <div>Questions?</div>
</body>

</html>