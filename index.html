<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <style>
    .container {
      position: relative;
      width: 100%;
      overflow: hidden;
      padding-top: 100%;
      /* 1:1 Aspect Ratio */
    }

    .responsive-iframe {
      position: absolute;
      top: 0;
      left: 0;
      bottom: 0;
      right: 0;
      width: 100%;
      height: 100%;
      border: none;
    }
  </style>
  <title>Participatory mobile music with smartphones</title>
  <style>
    .tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
.tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-0lax{text-align:left;vertical-align:top}
  </style>
  <link href="big.css" rel="stylesheet" type="text/css" />
  <link href="themes/charleston.css" rel="stylesheet" type="text/css" />

  <script src="js/index-citations-global.js"></script>
  <script>
    function run() {
      IndexCitations({
        referenceId: "#citations",
      });

      const citations = document.querySelectorAll(".citationLink");
      // TODO: update this to be the last slide whenever you make it
      citations.forEach((citation) => (citation.href = "#53"));

      const ref = document.querySelectorAll("#citations cite");

      ref.forEach((reference) => {
        var el = document.createElement("span");
        el.innerHTML = '<a href="javascript:history.back()">&#8627;</a>';
        insertAfter(reference, el);
      });
    }

    if (document.readyState != "loading") {
      run();
    } else {
      document.addEventListener("DOMContentLoaded", run);
    }

    function insertAfter(referenceNode, newNode) {
      referenceNode.parentNode.insertBefore(
        newNode,
        referenceNode.nextSibling
      );
    }
  </script>
  <script src="big.js"></script>
  <script src="js/lazysizes.min.js"></script>
</head>

<body>

  <div>
    <div>Using Distributed Technology to Make Music in the time of the Attention Economy</div>
    <div>
      <em> Tate Carson, MM, MFA </em>
    </div>
    <notes></notes>
  </div>

  <div>Theoretical Background</div>

  <div>Attention Economy</div>

  <div>Ecological Awareness</div>

  <div>Restorative Environments</div>

  <div>Distributed Internet</div>

  <div>Artistic Background</div>

  <div>Soundwalking</div>

  <div>GPS Soundwalks</div>

  <div>Distributed Internet</div>

  <div>Sonification</div>

  <div>Previous work</div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/nature3.jpg" alt="Sounds Aware" />

    <div>Sounds Aware (2019) - Version 1</div>

    <notes>Sounds Aware is a web application that runs on a smartphone and uses
      machine learning to detect human-made sound (anthrophony) and masks it
      with ambient music as a user walks around their environment. Though the
      model is pre-trained with the author’s local environmental sounds, the
      user can train the model further on their unique soundscape so that each
      user gets a personalized experience. After the training process, the
      user can listen to ambient music based on traits of the surrounding
      anthrophony. If the app senses less anthrophony and more biophony or
      geophony, then the music fades away, bringing the user’s attention to
      the anthrophony.</notes>
  </div>
  <div class="layout">
    <img src="images/soundsaware/walkingDog.jpg" alt="" />
    <notes>The idea for Sounds Aware came while walking with dog Lucy around the
      lakes by my house. When I first started walking her I would listen to
      podcast or music on headphones for the entire walk because I found it
      difficult to fill the time with my own thoughts. I would hear the sounds
      of nature occasionally coming through my music and this made me want to
      take the head phones out and just listen.</notes>
  </div>
  <div class="layout">
    <img src="images/soundsaware/nature.jpg" alt="" />

    <notes>The problem came when I tried to do that and realized there, while this
      is a beautiful bit of nature, it is by peoples houses and some major
      roads.</notes>
  </div>

  <div class="layout">
    <img src="images/soundsaware/construction.jpg" alt="" />
    <notes>So in addition the birds I could also hear the noise of lawnmowers,
      home construction and cars driving by.</notes>
  </div>
  <div class="layout">
    <video src="images/soundsaware/constructionVid.mp4" width="500px" controls></video>
    <notes>And sometimes it sounds like this. This made me want the best of both
      worlds. I wanted to create a system that would play music if it heard
      'noise' and play nothing if it heard nothing. This I thought would help
      me focus my attention more on nature and less on how much I didn't want
      to hear the noise. This inspired Sounds Aware.</notes>
  </div>
  <div>
    <blockquote>
      <p>
        To what extent might the technologies of communication, art and
        entertainment serve as 'prostheses' that would provide us with
        experiences of wilderness that would not only enrich our human
        identity but help us to preserve and expand the domain of the
        non-human world?
      </p>
      <cite>
        David Dunn. Wilderness as Reentrant Form: Thoughts on the Future of
        Electronic Art and Nature. Leonardo, (4):377, 1988.
      </cite>
    </blockquote>
    <div>- David Dunn</div>

    <notes> Composer David Dunn poses an inspirational question: </notes>
  </div>
  <div>
    A goal of Sounds Aware is to shift attention to geophonic and biophonic
    soundscape away from the anthrophonony.

    <notes>
      The goal of Sounds Aware is to bring the user’s awareness to the
      geophonic and biophonic soundscape, which is often so masked by noise
      pollution that it has fallen out of awareness for many of us. Sounds
      Aware seeks to shift the user’s concept of nature to something that has
      no starting or end- ing point; it is all around us. The app brings
      awareness by focusing attention on the environment. Because of the pre-
      dominance of eye culture [3], our reliance on seeing rather than
      listening as a primary means of sensing the world, it is a lot to ask of
      a person who might be uninterested in acoustic ecology to “just listen”
      to their environment. But, if you give them a tool that urges listening
      in the quieter places, where the natural world will be more audible,
      there is a better chance of them engaging with those sounds because the
      app focused their perception. Sounds Aware is a means of technologically
      mediated “ear cleaning,” as described by R. Murray Schafer in Ear
      Cleaning: Notes for an Experimental Music Course [13].
    </notes>
  </div>
  <div>
    <div>Noise Pollution</div>
    <div>
      <ul>
        <li>
          There is overwhelming evidence that exposure to environmental noise
          has adverse effects on the health of the population.<cite>World Health Organization, Burden of disease from
            environmental
            noise: Quantification of healthy life years lost in Europe. World
            Health Organization. Regional Office for Europe, 2011.
          </cite>
        </li>
        <li>
          Sounds Aware will make users more aware of how much harmful noise
          they experience in their daily lives.
        </li>
      </ul>
    </div>
    <notes>A 2011 World Health Organization (WHO) report found that “there is
      overwhelming evidence that exposure to environmental noise has adverse
      effects on the health of the population [10].” Sounds Aware shifts a
      users attention away from noise pollution and to nature, which may help
      mitigate adverse health effects caused by noise pollution.
      <br />
      While a reduction in environmental noise at the source would be the best
      way to solve noise pollution, masking the noise is a stopgap solution. A
      masking solution has been implemented by several projects [9, 15] but
      not yet with a mobile device. Sounds Aware implements a similar idea but
      with a mobile phone.
    </notes>
  </div>


  <div>
    <div>
      <ul>
        <li>
          Stress reduction can be aided by the experience of the natural
          environment by providing a ‘restorative environment’ that reduces
          the fatigue caused by directed attention.<cite>Stephen. Kaplan, “The restorative benefits of nature: toward an
            integrative framework.,” In: Journal of Environmental Psychology.,
            vol. 15, pp. 169–182, 1995.
          </cite>
        </li>
        <li>
          Bird sounds may provide restorative benefits.<cite>E. Ratcliffe, B. Gatersleben, and P. T. Sowden, “Bird
            sounds and
            their contributions to perceived attention restoration and stress
            recovery,” Journal of Environmental Psychology, vol. 36, pp.
            221–228, 2013.
          </cite>
        </li>
      </ul>
    </div>
    <notes>Psychologist Stephen Kaplan found that stress reduction can be aided by
      the experience of the natural environment by providing a ‘restorative
      environment’ that reduces the fatigue caused by directed attention [8].
      Kaplan did not mention sound directly, but a recent study by Eleanor
      Ratcliffe et al [12] has extended his research to show that certain bird
      sounds may provide restorative benefits.</notes>
  </div>

  <div>
    <div>R. Murray Schafer's Soundscape</div>
    <div>
      <ul>
        <li>rural landscape - hi-fi</li>
        <li>urban landscape - lo-fi</li>
      </ul>
    </div>
    <notes>R. Murray Schafer suggests that we should listen to the environment as
      a musical composition. He describes urban and rural soundscapes as lo-fi
      and hi-fi. A rural landscape is hi-fi because there is a low noise level
      and allows one to hear more clearly. When in lo-fi (urban) soundscapes
      we are deal- ing with a lot of sound masking and getting less
      discernible aural information [14]. Sounds Aware brings attention to
      that urban noise by masking it with music, possibly reducing its
      negative effects as described by the WHO report [10]. The music of
      Sounds Aware and Schafer’s ‘environment as musical composition’ combine
      as a duet to create a new un- heard work.</notes>
  </div>


  <div>
    <div>Audio Walks</div>
    <blockquote>
      <p>
        experiments and works that combine walking and listening to a mediated
        soundscape over headphones.
        <cite>J. Steindorf. Walk-Along with a Mediated Presence: The Audio Walk
          as a Mobile Method. Wi: Journal of Mobile Media, 2017.</cite>
      </p>
    </blockquote>
    <div>- Johanna Steindorf</div>
    <notes>
      Sounds Aware is further classified as an audio walk because it is a
      soundwalk mediated by technology. Johanna Steindorf describes audio
      walks as “experiments and works that combine walking and listening to a
      mediated sound- scape over headphones [16].” That an audio walk takes
      place using headphones is important because it adds “a second layer of
      private sound to any place and situation, there- fore transforming or
      enhancing the current spatial experience [16].” Sounds Aware mediates
      the public space through remediation of noise. The unique part of this
      audio walk is that the user is meant to be more aware when the composed
      ambient music is off. It is almost like a negative audio walk.
    </notes>
  </div>
  <div>Related Work</div>
  <div class="layout" style="
        grid-template-columns: repeat(6, 1fr);
        grid-template-rows: repeat(5, 1fr);
        grid-column-gap: 11px;
      ">
    <div style="grid-area: 1 / 1 / 3 / 7">
      The Quiet Walk - Alessandro Altavilla and Atau Tanaka
    </div>
    <img style="grid-area: 3 / 1 / 6 / 4" src="images/soundsaware/TQW-MapsOnApp-620x348.jpg" alt="" />
    <img style="grid-area: 3 / 4 / 6 / 7" src="images/soundsaware/TQW-MobileAppInUse-620x348.jpg" alt="" />
    <notes>
      The Quiet Walk [1], by Alessandro Altavilla and Atau Tanaka, is locative
      audio walk artwork for explorations of the urban landscape, where the
      goal is to find the quietest place in an urban location. The app
      notifies users if the surrounding sounds are too high. It also records
      the GPS locations of quiet places that are found so that the user can
      view a sound map of their walk.
    </notes>
  </div>
  <div class="layout" style="grid-template-rows: 25% 75%">
    <div>Ambient Walk - Chen, Bowers, Durrant</div>
    <div>
      <img src="images/soundsaware/ambientWalk.jpg" alt="" />
    </div>
    <notes>
      Chen, Bowers, Durrant created Ambient Walk [4], a mobile application
      that encourages mindful walking through sonification of biophysical
      data. The app plays ambient music dependent on users breathing patterns
      and the pace of walking. The authors intend for the music to keep a user
      aware of their ‘balancing status’ between walking and breathing. The
      intentions of Ambient Walk are very similar to Sounds Aware, though its
      intention is to raise the user’s awareness of one’s own
      mindfulness,instead of the soundscape.
    </notes>
  </div>

  <div>
    <div>Design</div>
    <div>
      <ul>
        <li>Tone.js</li>
      </ul>
    </div>
    <notes>Sounds Aware is built with Tone.js, a Web Audio API framework. There
      are a few downsides to web-based apps, such as cross-browser
      compatibility issues with microphone input, but a web app was chosen
      because a user might be more likely to try it if they do not have to
      download an app.</notes>
  </div>

  <div>
    <div>Data Tags</div>
    <div>
      <ul>
        <li>Geophony - wind, other weather, rain</li>
        <li>Anthrophony - cars, construction, human speech, AC, airplanes</li>
        <li>Biophony - insects, birds, large animal</li>
      </ul>
    </div>
    <notes>Each user starts off with an author-defined database of tagged sounds.
      To create this database each recording made was tagged (see Table 1)
      with a general sound category. Those sounds were then placed into
      broader categories of origin. This allowed the composition to treat
      sounds from different sources—geophony, anthrophony, and biophony—
      differently.
    </notes>
  </div>

  <div>
    <div>Machine listening</div>
    <ul>
      <li>Meyda.js - <a href="http://meydajs.org">http://meydajs.org</a></li>
    </ul>
    <notes>The app uses machine learning to identify sounds. The al- gorithm used
      is k-nearest neighbor. A Mel-Frequency Cep- stral Coefficients (MFCC)
      audio feature was used to com- pare sounds, implemented by Meyda.js1 , a
      JavaScript fea- ture extraction library. Using Meyda.js allowed the
      process- ing to be done on the client, allowing Sounds Aware to work
      offline when necessary.</notes>
  </div>

  <div>
    <div>Composition</div>
    <div>
      <ul>
        <li>Influenced by ambient music</li>
        <li>Influenced by Aeolian practices</li>
        <li>
          Tuned using La Monte Young's just intonation Well-Tuned Piano tuning
        </li>
      </ul>
    </div>

    <notes>The musical composition of Sounds Aware is influenced by ambient music.
      Synthesized sounds were used that would not be too jarring to jump in
      and out of and did not have an obvious beginning or ending. This type of
      synthesized sound blends in with the surrounding acoustic environment as
      a composition. The synthesized sounds are simple frequency modulation
      synthesis with reverb and delay effects. They are tuned to just
      intervals so they are more likely to coincide with tunings in nature,
      influenced by Aeolian practices [2] and La Monte Young [6].</notes>
  </div>

  <div class="layout" style="grid-template-rows: 25% 75%">
    <div>Mapping</div>
    <div>
      <img src="images/soundsaware/compDesign.svg" alt="" />
    </div>

    <notes>
      The app maps the loudness of the acoustic environment to the amplitude
      of the ambient composition (see Figure 2). The previous 200 loudness
      values are averaged and the am when a user was moving. If they had been
      added to the anthrophony the system would only work if the user was
      still and silent; this was a trade-off to allow for user mobil- ity,
      allowing them to find various soundscapes. More data plitude ramps to a
      given value over one second for signal smoothing. If Sounds Aware hears
      an anthrophonic sound, the amplitude is faded up to -3 dB. If it hears a
      geophonic sound, the amplitude of the geophonic sound is mapped onto the
      synthesized sounds amplitude, creating a wind chime ef- fect. Geophonic
      sounds also affect the modulation index and harmonicity of the frequency
      modulation synthesis, cre- ating a variety of timbres depending on the
      character of the current external soundscape. If a biophonic sound is
      recog- nized, the amplitude of the ambient wash is faded down to -59 dB,
      which is perceptibly silent when listened to in an urban environment.
    </notes>
  </div>

  <div>
    <div>What did I learn?</div>
    <ul>
      <li>The app would be more useful with user accounts.</li>
      <li>
        User training of the machine learning algorithm directly on the phone
        is not accurate enough to understand more than a few sounds but might
        be viable in the future.
      </li>
    </ul>
  </div>

  <div>Project Design</div>

  <div>Sounds Aware App Tour</div>

  <div>Home screen</div>

  <div class="layout">
    <video src="videos/home-page.mp4" width="500px" height="1000px" controls></video>
    <notes>The discover page shows each soundwalk created by other users</notes>
  </div>

  <div>Discover screen</div>

  <div class="layout">
    <video src="videos/discover-page.mov" width="500px" height="1000px" controls></video>
    <notes>The discover page shows each soundwalk created by other users</notes>
  </div>

  <div>Going on a soundwalk (walking the dog)</div>

  <div>
    <iframe width="1000px" height="700px" src="https://www.youtube.com/embed/mpr_-GG7zno" title="YouTube video player"
      frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
      allowfullscreen></iframe>

  </div>

  <div>Creating a soundwalk</div>

  <div class="layout">
    <video src="videos/stop-1.m4v" width="500px" controls></video>
    <notes>This is the start of the walk. Its pretty quiet but you can hear some noise in the background</notes>
  </div>
  <div class="layout">
    <video src="videos/stop1-phone.mov" width="500px" controls></video>
    <notes>and this is what the phone interaction looked like</notes>
  </div>

  <div class="layout">
    <video src="videos/lakeStop.m4v" width="500px" controls></video>
    <notes>Then there was another stop at the lake</notes>
  </div>


  <div class="layout">
    <video src="videos/lakeStop-phone.mov" width="500px" controls></video>
    <notes>and the phone looked like this</notes>
  </div>

  <div>How is the app made?</div>

  <div class="layout" style="grid-template-columns: 1fr;grid-template-rows:75% 25%;">
    <img src="images/soundsaware-v2/figma-1.png" alt="">
    <div>
      Planning Process - Figma
    </div>
    <notes>Before starting to develop the app I made a design in Figma, a tool for prototyping apps. The great thing
      about Figma is that it allows you to prototype interactions as well as the interface. This helps you reason about
      how the app will work before getting lost in the code.</notes>
  </div>

  <div class="layout" style="grid-template-columns: 1fr;grid-template-rows:75% 25%;">
    <img src="images/soundsaware-v2/figma-2.png" alt="">
    <div>
      Figma - Present mode
    </div>
    <notes>Present mode allows for testing the user interaction</notes>
  </div>

  <!-- 
    Tech

    Networking 
      IPFS 
      3box 

    Sound 
      Tone.js

    Sonification of survey answers
      - turning answers into music
      - distance of stop mapped to distance of panner node listener  
      - maybe show some code here
      use carbon.now.sh for nice looking code snippets
   -->
  <div class="layout" style="grid-template-columns: 1fr;grid-template-rows:75% 25%;">
    <img src="images/soundsaware-v2/ionic-framework.png" alt="">
    <div>
      Ionic Framework
    </div>
    <notes>
      Ionic Framework is a UI toolkit with prebuilt elements. It makes developing with react much easier. With one
      codebase you can target a mobile web app, a PWA or a native mobile app on IOS or Android.
      I used many of the components in my app
    </notes>
  </div>
  <div>
    IPFS
    <!-- TODO: add details about IPFS here -->
    <notes>This is what provides the distributed backend.</notes>
  </div>
  <div>
    <div>
      3Box
    </div>
    <ul>
      <li>Identity and Auth</li>
      <li>Storage</li>
      <li>Messaging</li>
    </ul>
    <notes>3Box is a framework that helps with building decentralized apps with IFPS. It provides an easy-to-use API
      that handles identity, authorization, storage and messaging.
      <br>
      The identity and auth allow for users to login to an app without the developer having to manage user data.
      <br>
      The storage API can hold data specific to one user such as documents, preferences or settings.
      <br>
      The messaging API allows for the creation of threads, a feed that can be subscribed to that create the basis for a
      distribute database.
    </notes>
  </div>
  <!-- TODO: show examples of my use of 3box -->
  <div class="layout" style="grid-template-columns: 50% 50%;">
    <img src="images/soundsaware-v2/code-screenshots/login.png" alt="">
    <div>Authorization</div>
    <notes>
      Here is the login function. We access portis, an ethereum wallet that allows users to login without having to
      install extra software. It helps to link your unique wallet address, which is your identity, to 3box in order to
      open your personal data box and space.
    </notes>
  </div>
  <div class="layout" style="grid-template-columns: 50% 50%;">
    <img src="images/soundsaware-v2/code-screenshots/joinThread.png" alt="">
    <div>Authorization - pt 2</div>
    <notes>
      After authentication we can open a thread that contains a list of other threads that contain all of the soundwalks
      created by users of the app. The selected soundwalk here is a way of recording which soundwalk a user was viewing
      or editing previously.
    </notes>
  </div>
  <div>Data Organization</div>
  <div style="grid-template-columns: 1fr;grid-template-rows:25% 75%;">
    <div>Public thread</div>
    <img src="images/soundsaware-v2/code-screenshots/threadDiagram.png" alt="">
    <notes>That thread that we connected to in the last slide is how each soundwalk is found. Every time a user creates
      a soundwalk this data gets added to the thread.</notes>
  </div>
  <div style="grid-template-columns: 1fr;grid-template-rows:25% 75%;">
    <div>Soundwalk thread</div>
    <img src="images/soundsaware-v2/code-screenshots/soundwalkThreadDiagram.png" alt="">
    <notes>The actual data for each soundwalk is stored in their own individual threads which have a reference in the
      original soundwalk thread. Here we can see the thread contains the name of the soundwalk, the location of one
      stop, and the survey answers that the user made for that stop.</notes>
  </div>
  <div>Survey Sonification</div>
  <div class="layout" style="grid-template-columns: 50% 50%;">
    <img src="images/soundsaware-v2/code-screenshots/survey1.png" alt="" />
    <img src="images/soundsaware-v2/code-screenshots/survey2.png" alt="" />

    <notes>Users are asked these questions every time they want to make a stop on their soundwalk. These questions are
      based off of Sarah Payne's Perceived Restorativeness Scale (PRSS) mentioned earlier. These questions provide the basis for the sonification of soundwalks that users can hear on the discover page.</notes>
  </div>

  <div>
    <div>
      Sound composition
    </div>
    <ul>
      <li>Wind chimes: hand chimes samples</li>
      <li>Wind:  Noise oscillator -> pitch shifter -> low pass filter -> high pass filter</li>
      <li>Background sounds: rustling leaves and waves samples</li>
    </ul>
    <notes>
      Before mentioning exactly how the survey data was mapped I'll speak a bit about what types of sounds you hear and the inspiration for them. I wanted to base the sonification on an imaginary wind chime because of these beautiful sounding chimes in my neighborhood that I hear while walking my dog. 

      <br>The wind chimes are driven by a number of chime samples in order to have fuller control over them.  
    </notes> 
  </div>
  <!-- total-serialism, geolib, nexusui, findClosest (mine) -->
  <!-- influenced by neighbors wind chime and la monte young tuning -->
  <div>
    <div>Wind Chimes</div>
    <ul>
      <li>Tuning - La Monte Young's Well Tuned Piano</li>
      <li>Note groupings from Young chords - Opening Chord, Magic Chord, etc. 
        <cite>
          Gann, Kyle. 1993. “La Monte Young’s The Well-Tuned Piano.” Perspectives of New Music 31 (1): 134–62.
      </cite> </li>
    </ul>
  </div>
  <div class="layout" style="grid-template-columns: 1fr;grid-template-rows:25% 50%;" >
    <div>Chord mappings</div>
    <img src="images/soundsaware-v2/code-screenshots/ChordMappingDiagram.svg" alt="">
      
      
    <notes>These chords change in the sonification depending on the average survey answers. I arranged them in an order I perceived to be more to less restorative sounding.</notes>
  </div>
  <div>Future Work</div>
  <div id="citations">References</div>
  <div>
    <div>Thank You</div>
    <em> tcarso2@lsu.edu </em>
    <a href="https://tatecarson.com" target="blank">https://tatecarson.com</a>
  </div>
  <div>Questions?</div>
</body>

</html>